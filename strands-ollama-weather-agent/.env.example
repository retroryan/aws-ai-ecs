# Model Provider Configuration
# Choose between "bedrock" (AWS) or "ollama" (local)
MODEL_PROVIDER=ollama

# Ollama Configuration (when MODEL_PROVIDER=ollama)
OLLAMA_MODEL=llama3.2
OLLAMA_HOST=http://localhost:11434
OLLAMA_TEMPERATURE=0.7
OLLAMA_MAX_TOKENS=4096
OLLAMA_TOP_P=0.9
OLLAMA_TIMEOUT=60

# AWS Bedrock Configuration (when MODEL_PROVIDER=bedrock)
BEDROCK_MODEL_ID=us.anthropic.claude-3-5-sonnet-20241022-v2:0
BEDROCK_REGION=us-west-2
BEDROCK_TEMPERATURE=0
# AWS credentials (if not using IAM role)
# AWS_ACCESS_KEY_ID=your_access_key
# AWS_SECRET_ACCESS_KEY=your_secret_key
# AWS_SESSION_TOKEN=your_session_token
# AWS_DEFAULT_REGION=us-west-2

# API Configuration
API_PORT=8090

# Logging
LOG_LEVEL=INFO

# System Prompt Type (default, agriculture, simple)
SYSTEM_PROMPT=default